{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n  \n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/pokemonclassification'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n \nimport shutil\nimport keras\nfrom sklearn.model_selection import train_test_split\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model \nimport matplotlib.pyplot as plt\nimport matplotlib.image as mig\nimport matplotlib\n\n# %% [raw]\n# \n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\nimport tensorflow\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mig\nimport matplotlib\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import plot_confusion_matrix\n\n#define all target names for classifaction\nroot_dir = ('/kaggle/input/pokemonclassification/PokemonData')\nclasses = os.listdir(root_dir)\n\n#Present array of image data within dataset\nc1_path = os.path.join(root_dir, classes[1])\nc1_data_path = [os.path.join(c1_path, img) for img in os.listdir(c1_path)]\nlen(c1_data_path)\n\nfor i in range(0, 5):\n    img = mig.imread(c1_data_path[i])\n\n    print(i, img.shape)\n    \n  \n\nIDG = ImageDataGenerator(validation_split=0.25 ,rescale = 1./255, rotation_range=20,width_shift_range=0.1,height_shift_range=0.1,shear_range=0.1,zoom_range=0.1,horizontal_flip=True,fill_mode='nearest')\n\ntrain_generator = IDG.flow_from_directory(root_dir,target_size=(128 ,128),batch_size=6820 ,class_mode='categorical')\nval = IDG.flow_from_directory(root_dir,target_size=(128,128),subset='validation',batch_size=8, class_mode='categorical')\n\n#Split the data into a training set and a test set\n((sample_x),(sample_y)) = next(train_generator)\nx_train, x_test, y_train, y_test = train_test_split(sample_x,sample_y,test_size=0.30, random_state=1)\ntrain_generator.reset()\ntrain_generator = IDG.flow_from_directory(root_dir,target_size=(128 ,128),batch_size=8 ,class_mode='categorical')\n\n#Present the images in the input form\nX, Y = next(train_generator)\nfor x,y in zip( X,Y ):  \n  plt.imshow(x)\n  plt.xlabel(classes[y.argmax()])\n  plt.show()\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n#training model\nimg_shape=(128,128,3)\n\n\nmodel = keras.Sequential(name='Pokemon_cls_5L_Net')\nmodel.add(keras.layers.Conv2D(64,3,input_shape=(img_shape),activation='relu'))\nmodel.add(keras.layers.MaxPool2D())\nmodel.add(keras.layers.Conv2D(32,3,strides=(2,2),activation='relu'))\nmodel.add(keras.layers.MaxPool2D())\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Conv2D(32,3,strides=(2,2),activation='relu'))\nmodel.add(keras.layers.MaxPool2D())\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dropout(0.2))\nmodel.add(keras.layers.Dense(1024,activation='relu'))\nmodel.add(keras.layers.Dense(512,activation='relu'))\nmodel.add(keras.layers.Dense(len(classes),activation='softmax'))\n\n\nmodel.summary()\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\nmodel.compile(optimizer='Nadam',\n             loss=tf.keras.losses.categorical_crossentropy,\n             metrics=['acc']\n             )\n \nhist = model.fit (train_generator ,validation_data=val, epochs=50)\n\n# %% [markdown]\n# \n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\nplt.style.use('fivethirtyeight')\nplt.figure(figsize=(14,14))\nplt.plot(hist.history['acc'],label='accuracy',color='green')\nplt.plot(hist.history['val_acc'], label='validation', color='red')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.yticks(np.arange(0, 1, step=0.04))\nplt.show()\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\nplt.style.use('fivethirtyeight')\nplt.figure(figsize=(14,14))\nplt.plot(hist.history['loss'],label='loss',color='green')\nplt.plot(hist.history['val_loss'], label='validation', color='red')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.yticks(np.arange(0, 8, step= 0.8))\nplt.show()\n\n# %% [markdown]\n# # classpokemon = train_generator.class_indices\n# classpokemon\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\nclasspokemon = train_generator.class_indices\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\nprint(\"Evaluate on test data\")\nresults = model.evaluate(x_test, y_test, batch_size=8)\nprint(\"test loss, test acc:\", results)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\nprint(\"Generate predictions for 3 samples\")\npredictions = model.predict(x_test[:3])\nprint(\"predictions shape:\", predictions.shape)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n\ny_pred = model.predict(x_test)\nconfusion_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\nprint(confusion_matrix)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\nmodel.save('model')\n\n# %% [markdown]\n# \n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\nimport zipfile\ndef zipdir(path, ziph):\n    # ziph is zipfile handle\n    for root, dirs, files in os.walk(path):\n        for file in files:\n            ziph.write(os.path.join(root, file))\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\nzipf = zipfile.ZipFile('model.zip', 'w', zipfile.ZIP_DEFLATED)\nzipdir('./model', zipf)\nzipf.close()","metadata":{"_uuid":"c63a7092-3b39-4431-b6d4-3efe6fdc3230","_cell_guid":"b6055891-3f99-4c6c-83e6-97d76a91159e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}